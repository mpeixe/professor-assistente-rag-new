import os
import streamlit as st
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from langchain_core.prompts import ChatPromptTemplate

# --- Fun√ß√µes de processamento de RAG ---

def setup_rag_system():
    """
    Configura e retorna a cadeia de RAG com m√∫ltiplos √≠ndices.
    Esta fun√ß√£o deve ser executada apenas uma vez.
    """
    try:
        # 1. PEGA A CHAVE DO OPENROUTER DOS SECRETS DO STREAMLIT
        api_key = st.secrets.get("OPENROUTER_API_KEY")
        if not api_key:
            st.error("Chave de API do OpenRouter n√£o encontrada. Por favor, configure-a nos 'Secrets' do Streamlit Cloud.")
            st.stop()

        # Estrutura para os dados das disciplinas
        disciplinas_data = {
            "biologia": {
                "url": "https://pt.wikipedia.org/wiki/Biologia_celular",
            },
            "fisica": {
                "url": "https://pt.wikipedia.org/wiki/F%C3%ADsica_qu%C3%A2ntica",
            }
        }

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)

        # Configura√ß√£o para embeddings via OpenRouter
        try:
            # Primeira tentativa: OpenAI Embeddings via OpenRouter
            embeddings = OpenAIEmbeddings(
                model="text-embedding-ada-002",
                openai_api_key=api_key,
                openai_api_base="https://openrouter.ai/api/v1"
            )
            st.info("‚úÖ Usando embeddings via OpenRouter")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Falha com OpenRouter embeddings: {e}")
            # Fallback: usar OpenAI diretamente (se tiver chave OpenAI)
            openai_key = st.secrets.get("OPENAI_API_KEY")
            if openai_key:
                embeddings = OpenAIEmbeddings(openai_api_key=openai_key)
                st.info("‚úÖ Usando embeddings via OpenAI direto")
            else:
                st.error("Nem OpenRouter nem OpenAI API keys encontradas!")
                st.stop()

        # Cria e armazena os √≠ndices em cache
        for disciplina, data in disciplinas_data.items():
            index_name = f"faiss_index_{disciplina}"
            if not os.path.exists(index_name):
                with st.spinner(f"Criando √≠ndice de {disciplina.capitalize()}..."):
                    loader = WebBaseLoader(data["url"])
                    documents = loader.load()

                    if not documents:
                        st.error(f"Falha ao carregar documentos para {disciplina}")
                        continue

                    # Limpando o texto antes de dividir
                    for doc in documents:
                        doc.page_content = doc.page_content.strip().replace("\n", " ").replace("  ", " ")

                    docs = text_splitter.split_documents(documents)
                    if not docs:
                        st.error(f"Falha ao dividir documentos para {disciplina}")
                        continue
                        
                    vectorstore = FAISS.from_documents(docs, embeddings)
                    vectorstore.save_local(index_name)
                    st.success(f"‚úÖ √çndice criado para {disciplina}")
            else:
                with st.spinner(f"Carregando √≠ndice de {disciplina.capitalize()}..."):
                    vectorstore = FAISS.load_local(
                        index_name, 
                        embeddings, 
                        allow_dangerous_deserialization=True
                    )
                    st.success(f"‚úÖ √çndice carregado para {disciplina}")
            data["vectorstore"] = vectorstore

        # Configura√ß√£o para ChatOpenAI via OpenRouter
        llm_classifier = ChatOpenAI(
            model="openai/gpt-3.5-turbo",
            temperature=0,
            openai_api_key=api_key,
            openai_api_base="https://openrouter.ai/api/v1"
        )
        
        prompt_classificador = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um assistente de roteamento que classifica perguntas sobre diferentes disciplinas.
            Sua tarefa √© identificar a qual disciplina a pergunta pertence. As disciplinas s√£o: biologia, fisica.
            Responda APENAS com o nome da disciplina, em letras min√∫sculas.
            Se n√£o se encaixar, responda 'outros'."""),
            ("human", "{input}")
        ])
        classificacao_chain = prompt_classificador | llm_classifier

        llm_responder = ChatOpenAI(
            model="openai/gpt-3.5-turbo",
            temperature=0,
            openai_api_key=api_key,
            openai_api_base="https://openrouter.ai/api/v1"
        )
        
        prompt_resposta = ChatPromptTemplate.from_template("""
        Responda √† pergunta do usu√°rio usando apenas o contexto fornecido.
        Se o contexto n√£o cont√©m informa√ß√µes suficientes, diga que n√£o tem informa√ß√£o suficiente.
        
        Contexto: {context}
        Pergunta: {input}
        
        Resposta:
        """)
        document_chain = create_stuff_documents_chain(llm_responder, prompt_resposta)

        return classificacao_chain, document_chain, disciplinas_data
    
    except Exception as e:
        st.error(f"Erro ao configurar o sistema RAG: {str(e)}")
        st.error("Verifique se as depend√™ncias est√£o instaladas corretamente:")
        st.code("""
        pip install streamlit
        pip install langchain
        pip install langchain-openai
        pip install langchain-community
        pip install faiss-cpu
        pip install beautifulsoup4
        """)
        st.stop()

def get_answer(question, classificacao_chain, document_chain, disciplinas_data):
    """
    Roteia a pergunta, busca no √≠ndice correto e gera a resposta.
    """
    try:
        # Classificar a pergunta
        disciplina_response = classificacao_chain.invoke({"input": question})
        disciplina = disciplina_response.content.strip().lower()
        
        st.info(f"üîç Pergunta classificada como: **{disciplina}**")

        if disciplina in disciplinas_data:
            vectorstore = disciplinas_data[disciplina]["vectorstore"]
            retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
            retrieval_chain = create_retrieval_chain(retriever, document_chain)
            response = retrieval_chain.invoke({"input": question})
            return response["answer"], disciplina
        else:
            return "Desculpe, a pergunta n√£o se encaixa em nenhuma das disciplinas que conhe√ßo (biologia, f√≠sica). Tente reformular sua pergunta.", None
    
    except Exception as e:
        return f"Erro ao processar a pergunta: {str(e)}", None

# --- Interface do Streamlit ---

st.set_page_config(
    page_title="Professor Assistente RAG",
    page_icon="üë®‚Äçüè´",
    layout="wide"
)

st.title("üë®‚Äçüè´ Professor Assistente RAG")
st.markdown("""
**Pergunte sobre Biologia ou F√≠sica e obtenha respostas baseadas em conhecimento especializado.**

üìö **Disciplinas dispon√≠veis:**
- üß¨ **Biologia** (Biologia Celular)
- ‚öõÔ∏è **F√≠sica** (F√≠sica Qu√¢ntica)
""")

# Inicializar o sistema RAG uma √∫nica vez
if "rag_system" not in st.session_state:
    with st.spinner("üîß Configurando sistema RAG..."):
        st.session_state.rag_system = setup_rag_system()

if st.session_state.rag_system:
    classificacao_chain, document_chain, disciplinas_data = st.session_state.rag_system

    # Entrada do usu√°rio
    with st.container():
        col1, col2 = st.columns([3, 1])
        
        with col1:
            user_question = st.text_input(
                "Digite sua pergunta:",
                placeholder="Ex: O que √© uma c√©lula eucariota? Como funciona o efeito fotoel√©trico?"
            )
        
        with col2:
            st.markdown("<br>", unsafe_allow_html=True)  # Espa√ßamento
            clear_button = st.button("üóëÔ∏è Limpar", use_container_width=True)

    if clear_button:
        st.rerun()

    if user_question:
        with st.spinner("ü§î Gerando resposta..."):
            answer, disciplina = get_answer(user_question, classificacao_chain, document_chain, disciplinas_data)

        if disciplina:
            st.markdown(f"### üìñ Resposta - {disciplina.capitalize()}")
        
        if answer.startswith("Erro"):
            st.error(f"‚ùå {answer}")
        else:
            st.success(f"‚úÖ {answer}")
            
        # Adicionar feedback do usu√°rio
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("üëç √ötil"):
                st.success("Obrigado pelo feedback!")
        with col2:
            if st.button("üëé N√£o √∫til"):
                st.info("Tente reformular sua pergunta para melhores resultados.")
        with col3:
            if st.button("üîÑ Nova pergunta"):
                st.rerun()